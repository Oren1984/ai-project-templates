# Module 2.5 — ROOT Template (Transformers Foundations)

**Module:** 2.5 — Transformers & Retrieval Foundations  
**Docs style:** English (single source of truth)  
**Goal:** Bridge between Module 2 (DL/NLP) and Module 3 (LLMs/Agents)

## Purpose
This ROOT template defines the standards for a minimal educational repo that demonstrates:
- Transformer inference
- Sentence embeddings
- Bi-encoder retrieval (in-memory)
- Cross-encoder reranking (top-k only)

## Constraints (must keep)
- No RAG pipeline
- No vector DB
- No agents
- No production infra
- Minimal dependencies
- Local demos only

## Expected Repo Shape
- README.md (short)
- SUMMARY.md (8–10 bullets)
- requirements.txt (minimal)
- src/ (4 scripts)
- docs/ (concepts + architecture + how to run)
- docs/internal/ (optional Hebrew personal summary)

## Output Guidelines
Outputs must remain short and focused:
- shapes
- similarity scores
- ordering / ranking

No plots required. No training loops.